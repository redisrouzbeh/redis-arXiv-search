{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e23fb70",
   "metadata": {},
   "source": [
    "# Create arXiv Embeddings\n",
    "\n",
    "In this notebook we will:\n",
    "\n",
    "1) Pull the arXiv dataset from Kaggle\n",
    "2) Perform data preprocessing and cleanup\n",
    "3) Create HuggingFace embeddings\n",
    "4) Create OpenAI embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fb67e09-4f42-409c-a17a-c083536e7e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: rfd\n"
     ]
    }
   ],
   "source": [
    "!rfd"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7f2ca3c-184a-4e40-9116-038917374171",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T17:33:04.390376Z",
     "start_time": "2024-04-18T17:33:04.147342Z"
    }
   },
   "source": [
    "!pipx install kaggle pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e92d9475",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T17:37:26.027520Z",
     "start_time": "2024-04-18T17:37:26.020038Z"
    }
   },
   "outputs": [],
   "source": [
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d7ad1a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T17:39:37.934601Z",
     "start_time": "2024-04-18T17:37:32.435970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/Cornell-University/arxiv\n",
      "License(s): CC0-1.0\n",
      "arxiv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d Cornell-University/arxiv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e0295ed",
   "metadata": {},
   "source": [
    "Unzip the file and there you have it!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93fa47f7",
   "metadata": {},
   "source": [
    "## 2 - Perform data preprocessing and cleanup"
   ]
  },
  {
   "cell_type": "code",
   "id": "cc20c14a",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-18T19:34:08.944674Z",
     "start_time": "2024-04-18T19:34:08.734893Z"
    }
   },
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "DATA_PATH = \"arxiv-metadata-oai-snapshot.json\"\n",
    "YEAR_CUTOFF = 2012\n",
    "YEAR_PATTERN = r\"(19|20[0-9]{2})\"\n",
    "ML_CATEGORY = \"cs.LG\"\n",
    "DATASET_SIZE=10000"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "05e20498",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-18T19:34:09.925357Z",
     "start_time": "2024-04-18T19:34:09.918912Z"
    }
   },
   "source": [
    "# Preprocessing function to clean data\n",
    "def process(paper: dict):\n",
    "    paper = json.loads(paper)\n",
    "    if paper['journal-ref']:\n",
    "        years = [int(year) for year in re.findall(YEAR_PATTERN, paper['journal-ref'])]\n",
    "        years = [year for year in years if (year <= 2023 and year >= 1991)]\n",
    "        year = min(years) if years else None\n",
    "    else:\n",
    "        year = None\n",
    "    return {\n",
    "        'id': paper['id'],\n",
    "        'title': paper['title'],\n",
    "        'year': year,\n",
    "        'authors': paper['authors'],\n",
    "        'categories': ','.join(paper['categories'].split(' ')),\n",
    "        'abstract': paper['abstract']\n",
    "    }\n",
    "\n",
    "# Data loading function\n",
    "def papers():\n",
    "    with open(DATA_PATH, 'r') as f:\n",
    "        for paper in f:\n",
    "            paper = process(paper)\n",
    "            if paper['year']:\n",
    "                if paper['year'] >= YEAR_CUTOFF and ML_CATEGORY in paper['categories']:\n",
    "                    yield paper"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "04abead5-2567-47ed-ac51-abb10ca4b4c3",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-18T19:34:22.742142Z",
     "start_time": "2024-04-18T19:34:10.987560Z"
    }
   },
   "source": [
    "# Load dataset into Pandas dataframe and take a sample\n",
    "df = pd.DataFrame(papers()).sample(n=DATASET_SIZE)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "aee130cd",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-18T19:34:24.398243Z",
     "start_time": "2024-04-18T19:34:24.334610Z"
    }
   },
   "source": [
    "# Avg length of the abstracts - num tokens\n",
    "df.abstract.apply(lambda a: len(a.split())).mean()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172.4068"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "1415eabf-965a-465a-98ec-7cdec531f933",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-18T19:34:25.807410Z",
     "start_time": "2024-04-18T19:34:25.802678Z"
    }
   },
   "source": [
    "# Helper function to clean the description!\n",
    "def clean_description(description: str):\n",
    "    if not description:\n",
    "        return \"\"\n",
    "    # remove unicode characters\n",
    "    description = description.encode('ascii', 'ignore').decode()\n",
    "\n",
    "    # remove punctuation\n",
    "    description = re.sub('[%s]' % re.escape(string.punctuation), ' ', description)\n",
    "\n",
    "    # clean up the spacing\n",
    "    description = re.sub('\\s{2,}', \" \", description)\n",
    "\n",
    "    # remove urls\n",
    "    #description = re.sub(\"https*\\S+\", \" \", description)\n",
    "\n",
    "    # remove newlines\n",
    "    description = description.replace(\"\\n\", \" \")\n",
    "\n",
    "    # remove all numbers\n",
    "    #description = re.sub('\\w*\\d+\\w*', '', description)\n",
    "\n",
    "    # split on capitalized words\n",
    "    description = \" \".join(re.split('(?=[A-Z])', description))\n",
    "\n",
    "    # clean up the spacing again\n",
    "    description = re.sub('\\s{2,}', \" \", description)\n",
    "\n",
    "    # make all words lowercase\n",
    "    description = description.lower()\n",
    "\n",
    "    return description.strip()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:27: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:27: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/var/folders/mk/41lqkkzj29d7jlzz09x5gb300000gp/T/ipykernel_38526/1561391420.py:12: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  description = re.sub('\\s{2,}', \" \", description)\n",
      "/var/folders/mk/41lqkkzj29d7jlzz09x5gb300000gp/T/ipykernel_38526/1561391420.py:27: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  description = re.sub('\\s{2,}', \" \", description)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "0ad625b2-c624-4dc6-bf42-d2f671f760c4",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-18T19:34:39.051846Z",
     "start_time": "2024-04-18T19:34:38.404813Z"
    }
   },
   "source": [
    "# Apply the cleaner method on both title and abstract\n",
    "texts = df.apply(lambda r: clean_description(r['title'] + ' ' + r['abstract']), axis=1).tolist()"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1204072-fcf3-4fca-bf09-b7db67067cb8",
   "metadata": {},
   "source": [
    "## 3 - Creating Hugging Face Embeddings\n",
    "\n",
    "First up, we will use the built-in RedisVL vectorizer to create embeddings from huggingface."
   ]
  },
  {
   "cell_type": "code",
   "id": "727e684e66a80316",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T19:34:42.109136Z",
     "start_time": "2024-04-18T19:34:41.286926Z"
    }
   },
   "source": [
    "!pipx install redisvl==0.1.0\n",
    "!pipx install transformers\n",
    "!pipx install sentence-transformers --include-deps"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[?25l"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'redisvl' already seems to be installed. Not modifying existing installation\r\n",
      "in '/Users/rouzbeh.farahmand/.local/pipx/venvs/redisvl'. Pass '--force' to\r\n",
      "force installation.\r\n",
      "\u001B[?25h\u001B[?25l'transformers' already seems to be installed. Not modifying existing\r\n",
      "installation in '/Users/rouzbeh.farahmand/.local/pipx/venvs/transformers'.\r\n",
      "Pass '--force' to force installation.\r\n",
      "\u001B[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[?25l'sentence-transformers' already seems to be installed. Not modifying existing\r\n",
      "installation in\r\n",
      "'/Users/rouzbeh.farahmand/.local/pipx/venvs/sentence-transformers'. Pass\r\n",
      "'--force' to force installation.\r\n",
      "\u001B[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fe1e334-4987-4144-a1be-defef084509f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[?25l/Users/rouzbeh.farahmand/.local/bin has been been added to PATH, but you need\n",
      "    to open a new terminal or re-login for this PATH change to take effect.\n",
      "\n",
      "You will need to open a new terminal or re-login for the PATH changes to take\n",
      "effect.\n",
      "\n",
      "Otherwise pipx is ready to go! âœ¨ ðŸŒŸ âœ¨\n",
      "\u001B[?25h"
     ]
    }
   ],
   "source": [
    "!pipx ensurepath"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T19:26:28.956667Z",
     "start_time": "2024-04-18T19:26:18.382911Z"
    }
   },
   "cell_type": "code",
   "source": "!exec /bin/zsh",
   "id": "71b38249447bb702",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[m\u001B[m\u001B[m\u001B[Jrouzbeh.farahmand@rouzbeh data % \u001B[K\u001B[?2004h                                          \u001B[?2004l\r\n",
      "\u001B[m\u001B[m\u001B[m\u001B[Jrouzbeh.farahmand@rouzbeh data % \u001B[K\u001B[?2004h\u001B[?2004l                                  \r\n",
      "\u001B[m\u001B[m\u001B[m\u001B[Jrouzbeh.farahmand@rouzbeh data % \u001B[K\u001B[?2004h                                          "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T19:27:06.501100Z",
     "start_time": "2024-04-18T19:27:05.918392Z"
    }
   },
   "cell_type": "code",
   "source": "!pip3",
   "id": "5aa07e9f65616625",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Usage:   \r\n",
      "  pip3 <command> [options]\r\n",
      "\r\n",
      "Commands:\r\n",
      "  install                     Install packages.\r\n",
      "  download                    Download packages.\r\n",
      "  uninstall                   Uninstall packages.\r\n",
      "  freeze                      Output installed packages in requirements format.\r\n",
      "  inspect                     Inspect the python environment.\r\n",
      "  list                        List installed packages.\r\n",
      "  show                        Show information about installed packages.\r\n",
      "  check                       Verify installed packages have compatible dependencies.\r\n",
      "  config                      Manage local and global configuration.\r\n",
      "  search                      Search PyPI for packages.\r\n",
      "  cache                       Inspect and manage pip's wheel cache.\r\n",
      "  index                       Inspect information available from package indexes.\r\n",
      "  wheel                       Build wheels from your requirements.\r\n",
      "  hash                        Compute hashes of package archives.\r\n",
      "  completion                  A helper command used for command completion.\r\n",
      "  debug                       Show information useful for debugging.\r\n",
      "  help                        Show help for commands.\r\n",
      "\r\n",
      "General Options:\r\n",
      "  -h, --help                  Show help.\r\n",
      "  --debug                     Let unhandled exceptions propagate outside the\r\n",
      "                              main subroutine, instead of logging them to\r\n",
      "                              stderr.\r\n",
      "  --isolated                  Run pip in an isolated mode, ignoring\r\n",
      "                              environment variables and user configuration.\r\n",
      "  --require-virtualenv        Allow pip to only run in a virtual environment;\r\n",
      "                              exit with an error otherwise.\r\n",
      "  --python <python>           Run pip with the specified Python interpreter.\r\n",
      "  -v, --verbose               Give more output. Option is additive, and can be\r\n",
      "                              used up to 3 times.\r\n",
      "  -V, --version               Show version and exit.\r\n",
      "  -q, --quiet                 Give less output. Option is additive, and can be\r\n",
      "                              used up to 3 times (corresponding to WARNING,\r\n",
      "                              ERROR, and CRITICAL logging levels).\r\n",
      "  --log <path>                Path to a verbose appending log.\r\n",
      "  --no-input                  Disable prompting for input.\r\n",
      "  --keyring-provider <keyring_provider>\r\n",
      "                              Enable the credential lookup via the keyring\r\n",
      "                              library if user input is allowed. Specify which\r\n",
      "                              mechanism to use [disabled, import, subprocess].\r\n",
      "                              (default: disabled)\r\n",
      "  --proxy <proxy>             Specify a proxy in the form\r\n",
      "                              scheme://[user:passwd@]proxy.server:port.\r\n",
      "  --retries <retries>         Maximum number of retries each connection should\r\n",
      "                              attempt (default 5 times).\r\n",
      "  --timeout <sec>             Set the socket timeout (default 15 seconds).\r\n",
      "  --exists-action <action>    Default action when a path already exists:\r\n",
      "                              (s)witch, (i)gnore, (w)ipe, (b)ackup, (a)bort.\r\n",
      "  --trusted-host <hostname>   Mark this host or host:port pair as trusted,\r\n",
      "                              even though it does not have valid or any HTTPS.\r\n",
      "  --cert <path>               Path to PEM-encoded CA certificate bundle. If\r\n",
      "                              provided, overrides the default. See 'SSL\r\n",
      "                              Certificate Verification' in pip documentation\r\n",
      "                              for more information.\r\n",
      "  --client-cert <path>        Path to SSL client certificate, a single file\r\n",
      "                              containing the private key and the certificate\r\n",
      "                              in PEM format.\r\n",
      "  --cache-dir <dir>           Store the cache data in <dir>.\r\n",
      "  --no-cache-dir              Disable the cache.\r\n",
      "  --disable-pip-version-check\r\n",
      "                              Don't periodically check PyPI to determine\r\n",
      "                              whether a new version of pip is available for\r\n",
      "                              download. Implied with --no-index.\r\n",
      "  --no-color                  Suppress colored output.\r\n",
      "  --no-python-version-warning\r\n",
      "                              Silence deprecation warnings for upcoming\r\n",
      "                              unsupported Pythons.\r\n",
      "  --use-feature <feature>     Enable new functionality, that may be backward\r\n",
      "                              incompatible.\r\n",
      "  --use-deprecated <feature>  Enable deprecated functionality, that will be\r\n",
      "                              removed in the future.\r\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f60c9e3a-9f56-47f0-9f5b-5a625229702b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T19:18:44.083312Z",
     "start_time": "2024-04-18T19:18:43.950631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30c4a7ed-cc3a-405d-9afa-21de7b387528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "id": "ef747be9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T19:34:56.765953Z",
     "start_time": "2024-04-18T19:34:54.686897Z"
    }
   },
   "source": [
    "from redisvl.utils.vectorize import HFTextVectorizer\n",
    "\n",
    "hf = HFTextVectorizer(model=\"sentence-transformers/all-mpnet-base-v2\")"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "249ad360",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-18T19:40:39.294777Z",
     "start_time": "2024-04-18T19:34:57.765867Z"
    }
   },
   "source": [
    "# Create embeddings from the title and abstract\n",
    "embeddings = hf.embed_many(texts)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "be859336-06dc-46ff-9452-716604105f1f",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-18T19:53:19.564794Z",
     "start_time": "2024-04-18T19:53:19.542133Z"
    }
   },
   "source": [
    "embeddings[0][:10]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.014411247335374355,\n",
       " 0.01784348115324974,\n",
       " -0.006457224488258362,\n",
       " 0.044496506452560425,\n",
       " -0.015901479870080948,\n",
       " 0.012798929587006569,\n",
       " 0.028422124683856964,\n",
       " -0.038135871291160583,\n",
       " 0.025910435244441032,\n",
       " -0.0353618748486042]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "f7b4974a",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-18T19:54:34.683095Z",
     "start_time": "2024-04-18T19:54:34.636505Z"
    }
   },
   "source": [
    "# Add embeddings to df\n",
    "df = df.reset_index().drop('index', axis=1)\n",
    "df['huggingface'] = embeddings"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T19:54:36.627925Z",
     "start_time": "2024-04-18T19:54:36.623501Z"
    }
   },
   "cell_type": "code",
   "source": "df['cohere'] = embeddings",
   "id": "b0eaf689a56f0a42",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T19:54:37.603489Z",
     "start_time": "2024-04-18T19:54:37.599207Z"
    }
   },
   "cell_type": "code",
   "source": "df['openai'] = embeddings",
   "id": "4f952419ec18761f",
   "outputs": [],
   "execution_count": 20
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34787921-62ec-4279-ab9b-fcd9290f6b2f",
   "metadata": {},
   "source": [
    "## OpenAI Embeddings\n",
    "\n",
    "Next, we will use OpenAI Embeddings for our arXiv papers. You will need to set your OpenAI API Key below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff3304a9-a492-4a9d-9d90-ebd66a89968c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from redisvl.utils.vectorize import OpenAITextVectorizer\n",
    "\n",
    "oai = OpenAITextVectorizer(api_config={\"api_key\": \"YOUR API KEY HERE\"})\n",
    "\n",
    "embeddings = await oai.aembed_many(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1de9f18-8dd0-43c4-9e94-436f0751389e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3c84a46-d118-4f99-adc5-c1b524c9fe7c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.034895237535238266,\n",
       " 0.0013622459955513477,\n",
       " 0.025790950283408165,\n",
       " -0.031307876110076904,\n",
       " -0.0186705831438303,\n",
       " 0.027937931939959526,\n",
       " 0.008866488933563232,\n",
       " 0.01263049989938736,\n",
       " -0.03155247122049332,\n",
       " -0.022502535954117775]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c25023d9-29b4-49f0-b2f6-d26ba18c4461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['openai'] = embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa668f02",
   "metadata": {},
   "source": [
    "## Cohere Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb328965",
   "metadata": {},
   "outputs": [],
   "source": [
    "from redisvl.utils.vectorize import CohereTextVectorizer\n",
    "\n",
    "co = CohereTextVectorizer(\n",
    "    model=\"embed-multilingual-v3.0\",\n",
    "    api_config={\"api_key\": \"YOUR API KEY HERE\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f48d63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = co.embed_many(texts, input_type=\"search_document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a290ff8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdb5588b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44d00656",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cohere'] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "baf0e5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>huggingface</th>\n",
       "      <th>openai</th>\n",
       "      <th>cohere</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1812.02855</td>\n",
       "      <td>Progressive Sampling-Based Bayesian Optimizati...</td>\n",
       "      <td>2017</td>\n",
       "      <td>Xueqiang Zeng, Gang Luo</td>\n",
       "      <td>cs.LG,stat.ML</td>\n",
       "      <td>Purpose: Machine learning is broadly used fo...</td>\n",
       "      <td>[0.005483315791934729, 0.06285043805837631, -0...</td>\n",
       "      <td>[-0.034895237535238266, 0.0013622459955513477,...</td>\n",
       "      <td>[-0.0146865845, -0.023620605, 0.009109497, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1708.01422</td>\n",
       "      <td>Exploring the Function Space of Deep-Learning ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Bo Li and David Saad</td>\n",
       "      <td>cond-mat.dis-nn,cs.LG</td>\n",
       "      <td>The function space of deep-learning machines...</td>\n",
       "      <td>[-0.022667571902275085, 0.04551266133785248, -...</td>\n",
       "      <td>[-0.017496585845947266, -0.009123609401285648,...</td>\n",
       "      <td>[0.020828247, -0.004623413, -0.009017944, 0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001.00561</td>\n",
       "      <td>PrivacyNet: Semi-Adversarial Networks for Mult...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Vahid Mirjalili, Sebastian Raschka, Arun Ross</td>\n",
       "      <td>cs.CV,cs.CR,cs.LG</td>\n",
       "      <td>Recent research has established the possibil...</td>\n",
       "      <td>[-0.004289142321795225, 0.1055050864815712, -0...</td>\n",
       "      <td>[-0.0183021891862154, 0.004181693773716688, 0....</td>\n",
       "      <td>[0.024093628, 0.0047302246, -0.032104492, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003.01300</td>\n",
       "      <td>Few-Shot Relation Learning with Attention for ...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Sion An, Soopil Kim, Philip Chikontwe and Sang...</td>\n",
       "      <td>eess.SP,cs.LG</td>\n",
       "      <td>Brain-Computer Interfaces (BCI) based on Ele...</td>\n",
       "      <td>[-0.033013615757226944, 0.05156606808304787, -...</td>\n",
       "      <td>[-0.036494333297014236, 0.003500517923384905, ...</td>\n",
       "      <td>[-0.045196533, -0.009727478, 0.016662598, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902.03896</td>\n",
       "      <td>Reconstructing dynamical networks via feature ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>Marc G. Leguia and Zoran Levnajic and Ljupco T...</td>\n",
       "      <td>math.DS,cs.LG,cs.SI,physics.soc-ph,stat.ML</td>\n",
       "      <td>Empirical data on real complex systems are b...</td>\n",
       "      <td>[-0.07013913244009018, 0.05345052108168602, -0...</td>\n",
       "      <td>[-0.017974110320210457, 0.010659225285053253, ...</td>\n",
       "      <td>[0.05041504, 0.03857422, -0.00983429, 0.029983...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              title  year  \\\n",
       "0  1812.02855  Progressive Sampling-Based Bayesian Optimizati...  2017   \n",
       "1  1708.01422  Exploring the Function Space of Deep-Learning ...  2018   \n",
       "2  2001.00561  PrivacyNet: Semi-Adversarial Networks for Mult...  2020   \n",
       "3  2003.01300  Few-Shot Relation Learning with Attention for ...  2020   \n",
       "4  1902.03896  Reconstructing dynamical networks via feature ...  2019   \n",
       "\n",
       "                                             authors  \\\n",
       "0                            Xueqiang Zeng, Gang Luo   \n",
       "1                               Bo Li and David Saad   \n",
       "2      Vahid Mirjalili, Sebastian Raschka, Arun Ross   \n",
       "3  Sion An, Soopil Kim, Philip Chikontwe and Sang...   \n",
       "4  Marc G. Leguia and Zoran Levnajic and Ljupco T...   \n",
       "\n",
       "                                   categories  \\\n",
       "0                               cs.LG,stat.ML   \n",
       "1                       cond-mat.dis-nn,cs.LG   \n",
       "2                           cs.CV,cs.CR,cs.LG   \n",
       "3                               eess.SP,cs.LG   \n",
       "4  math.DS,cs.LG,cs.SI,physics.soc-ph,stat.ML   \n",
       "\n",
       "                                            abstract  \\\n",
       "0    Purpose: Machine learning is broadly used fo...   \n",
       "1    The function space of deep-learning machines...   \n",
       "2    Recent research has established the possibil...   \n",
       "3    Brain-Computer Interfaces (BCI) based on Ele...   \n",
       "4    Empirical data on real complex systems are b...   \n",
       "\n",
       "                                         huggingface  \\\n",
       "0  [0.005483315791934729, 0.06285043805837631, -0...   \n",
       "1  [-0.022667571902275085, 0.04551266133785248, -...   \n",
       "2  [-0.004289142321795225, 0.1055050864815712, -0...   \n",
       "3  [-0.033013615757226944, 0.05156606808304787, -...   \n",
       "4  [-0.07013913244009018, 0.05345052108168602, -0...   \n",
       "\n",
       "                                              openai  \\\n",
       "0  [-0.034895237535238266, 0.0013622459955513477,...   \n",
       "1  [-0.017496585845947266, -0.009123609401285648,...   \n",
       "2  [-0.0183021891862154, 0.004181693773716688, 0....   \n",
       "3  [-0.036494333297014236, 0.003500517923384905, ...   \n",
       "4  [-0.017974110320210457, 0.010659225285053253, ...   \n",
       "\n",
       "                                              cohere  \n",
       "0  [-0.0146865845, -0.023620605, 0.009109497, 0.0...  \n",
       "1  [0.020828247, -0.004623413, -0.009017944, 0.06...  \n",
       "2  [0.024093628, 0.0047302246, -0.032104492, 0.04...  \n",
       "3  [-0.045196533, -0.009727478, 0.016662598, 0.00...  \n",
       "4  [0.05041504, 0.03857422, -0.00983429, 0.029983...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "id": "9d149609",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T19:54:54.440921Z",
     "start_time": "2024-04-18T19:54:54.386507Z"
    }
   },
   "source": [
    "d = df.to_dict('records')"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "6037246f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T19:55:07.508045Z",
     "start_time": "2024-04-18T19:54:55.551524Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "# Write to file\n",
    "\n",
    "with open(\"arxiv-papers-10000.json\", \"w\") as f:\n",
    "    json.dump(d, f)"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "75e4e60b5dbaa4eb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "1101703b484e21b4c7da4bb676c119e6751760496c5c0670e93208ab08ae0e96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
